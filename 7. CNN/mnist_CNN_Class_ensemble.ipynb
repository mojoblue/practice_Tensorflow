{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "    \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "            \n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            \n",
    "            # img 28x28x1 (black/white)\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "            \n",
    "            # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "            \n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "            \n",
    "            # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "            \n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "            \n",
    "            # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "            \n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "            \n",
    "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "            \n",
    "            # L4 Fully Connected Layer 4 * 4 * 128 inputs -> 625 outputs\n",
    "            W4 = tf.get_variable(\"W4\", shape = [128 * 4 * 4, 625], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "            \n",
    "            # L5 Final FC 625 inputs -> 10 outputs\n",
    "            W5 = tf.get_variable(\"W5\", shape=[625, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            self.logits = tf.matmul(L4, W5) + b5\n",
    "            \n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "            \n",
    "            correct_prediction = tf.equal(tf.argmax(self.logits,1), tf.argmax(self.Y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            \n",
    "            \n",
    "    def predict(self, x_test, keep_prob=1.0):\n",
    "        return self.sess.run(self.logits, \n",
    "                             feed_dict={self.X: x_test, self.keep_prob: keep_prob})\n",
    "    \n",
    "    def get_accuracy(self, x_test, y_test, keep_prob=1.0):\n",
    "        return self.sess.run(self.accuracy,\n",
    "                            feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prob})\n",
    "    \n",
    "    def train(self, x_data, y_data, keep_prob=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], \n",
    "                             feed_dict={self.X: x_data, self.Y: y_data, self.keep_prob: keep_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "models = []\n",
    "num_models = 10\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started!\n",
      "Epoch: 0001 cost = [0.44416016 0.42338538 0.51972621 0.37462941 0.41140284 0.37903619\n",
      " 0.41166199 0.4196968  0.37931438 0.44122714]\n",
      "Epoch: 0002 cost = [0.09529306 0.09591528 0.08922284 0.1003866  0.09929043 0.10070236\n",
      " 0.0908242  0.09701668 0.09853249 0.09442774]\n",
      "Epoch: 0003 cost = [0.07155774 0.07232798 0.06386882 0.07208786 0.0744542  0.0760129\n",
      " 0.06493963 0.07115802 0.07244567 0.06942201]\n",
      "Epoch: 0004 cost = [0.06021103 0.05776654 0.05180711 0.06079485 0.06204046 0.06417782\n",
      " 0.05336903 0.05873786 0.06094326 0.0574154 ]\n",
      "Epoch: 0005 cost = [0.05256251 0.05213467 0.04454627 0.05112329 0.05433941 0.05274705\n",
      " 0.04972    0.05129889 0.0516603  0.04805816]\n",
      "Epoch: 0006 cost = [0.04432859 0.04665918 0.04129861 0.04501207 0.04728005 0.04757883\n",
      " 0.04354326 0.04862034 0.0461798  0.04468001]\n",
      "Epoch: 0007 cost = [0.04272311 0.04225946 0.03674225 0.0441454  0.04173977 0.04219351\n",
      " 0.03941707 0.04159767 0.04218021 0.03924361]\n",
      "Epoch: 0008 cost = [0.03846021 0.03822807 0.03389096 0.03943134 0.03863449 0.03930585\n",
      " 0.0349183  0.03910189 0.03914624 0.03807758]\n",
      "Epoch: 0009 cost = [0.03549291 0.03576991 0.03275305 0.03359307 0.03480458 0.03755271\n",
      " 0.03381055 0.03633195 0.03426449 0.03434693]\n",
      "Epoch: 0010 cost = [0.03393696 0.03280291 0.02940837 0.03362357 0.03482121 0.03424735\n",
      " 0.0316786  0.03498813 0.03358102 0.03301604]\n",
      "Epoch: 0011 cost = [0.03166705 0.03189863 0.02909582 0.0331649  0.03133741 0.03188437\n",
      " 0.0305864  0.03364602 0.03077495 0.02958795]\n",
      "Epoch: 0012 cost = [0.03027526 0.03061275 0.02649784 0.02906073 0.02973585 0.03039067\n",
      " 0.02795006 0.03063077 0.03068023 0.0306377 ]\n",
      "Epoch: 0013 cost = [0.0296165  0.02974152 0.02670001 0.02904635 0.02866653 0.02951667\n",
      " 0.02665598 0.02871153 0.02927492 0.02598856]\n",
      "Epoch: 0014 cost = [0.02627878 0.02708953 0.02319162 0.02688387 0.02655187 0.02664351\n",
      " 0.02578529 0.02637988 0.02477308 0.02406159]\n",
      "Epoch: 0015 cost = [0.02668904 0.02480916 0.0243591  0.02537076 0.0253382  0.02671552\n",
      " 0.02550947 0.02725508 0.02565323 0.02506296]\n",
      "Learning Finished!\n",
      "0 Accuracy: 0.9936\n",
      "1 Accuracy: 0.9933\n",
      "2 Accuracy: 0.9938\n",
      "3 Accuracy: 0.9937\n",
      "4 Accuracy: 0.993\n",
      "5 Accuracy: 0.9931\n",
      "6 Accuracy: 0.993\n",
      "7 Accuracy: 0.9942\n",
      "8 Accuracy: 0.992\n",
      "9 Accuracy: 0.9937\n",
      "Ensemble Accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # train each model\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "    \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
    "    \n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros([test_size, 10])\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(mnist.test.images, mnist.test.labels))\n",
    "    p = m.predict(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "ensemble_correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "\n",
    "print('Ensemble Accuracy:', sess.run(ensemble_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
